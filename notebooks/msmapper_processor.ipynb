{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "# Processor requirements\n",
    "# The first two cells must be code cells, inpath and outpath define the scan file location and output location\n",
    "# inpath = '/dls/i16/data/2025/mm41580-1/processed/1114510_msmapper.nxs'\n",
    "inpath = '/dls/i16/data/2025/mm41580-1/1114510.nxs'\n",
    "inpath = '/dls/i16/data/2025/mm41697-1/1116348.nxs'\n",
    "outpath = \"\"\n",
    "\n",
    "inpath = '/dls/science/groups/das/ExampleData/hdfmap_tests/i16/1116988.nxs'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot msmapper HKL cuts\n",
    "\n",
    "This notebook automatically loads remapped HKL volumes resulting from the MillerSpaceMapper software on I16 and plots cuts along the pricipal axes.\n",
    "\n",
    "See https://confluence.diamond.ac.uk/display/I16/HKL+Mapping\n",
    "\n",
    "This notebook is processed via the gda-zocalo-connector service and started at the end of a scan. The notebook is run in the `$ module load mmg` python environment giving it access to [mmg_toolbox](https://github.com/DiamondLightSource/mmg_toolbox) and other common python packages."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "from mmg_toolbox import data_file_reader, module_info\n",
    "from mmg_toolbox.utils import fitting\n",
    "from mmg_toolbox.plotting.matplotlib import set_plot_defaults\n",
    "\n",
    "set_plot_defaults()  # set custom matplotlib rcParams\n",
    "\n",
    "def md(string):\n",
    "    return display(Markdown(string))\n",
    "\n",
    "print(module_info())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# load scan file\n",
    "scan = data_file_reader(inpath)\n",
    "\n",
    "md(scan.format('# {beamline} Scan: {scan_number:.0f}\\n*{filepath}*'))\n",
    "\n",
    "# Time\n",
    "start = scan('start_time')\n",
    "stop = scan('end_time')\n",
    "duration = stop - start\n",
    "\n",
    "# Create table\n",
    "tab = '| field | metadata |\\n| --- | --- |\\n'\n",
    "for s in str(scan).split('\\n'):\n",
    "    if '=' in s:\n",
    "        tab += '| %s |\\n' % s.replace('=', '|')\n",
    "\n",
    "tab += '|**start time** | %s |\\n' % start.strftime('%Y-%m-%d %H:%M')\n",
    "tab += '|**end time** | %s |\\n' % stop.strftime('%Y-%m-%d %H:%M')\n",
    "tab += '|**duration** | %s |\\n' % duration\n",
    "\n",
    "md(tab)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "md('# Default Plot')\n",
    "if 'volume' not in scan.map:\n",
    "    scan.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# If scan is a standard nexus file, not a remapped file, look for the remapped file in the processing folder\n",
    "\n",
    "if 'volume' in scan.map:\n",
    "    remap = scan\n",
    "    print('File contains remapped data')\n",
    "else:\n",
    "    # Find remapped files\n",
    "    proc_dir = os.path.dirname(scan.filename) + '/processed/'\n",
    "    for ntries in range(10):\n",
    "        # remapping may take some time, so keep checking until finished\n",
    "        files = [proc_dir + file for file in os.listdir(proc_dir)]\n",
    "        scn = str(scan.scan_number())\n",
    "        mapper_files = [\n",
    "            file for file in files\n",
    "            if file.endswith('.nxs') and scn in file and\n",
    "               'volume' in data_file_reader(file).map\n",
    "        ]\n",
    "        if len(mapper_files) > 0:\n",
    "            remap = data_file_reader(mapper_files[0])\n",
    "            break\n",
    "        else:\n",
    "            print('Remapped file does not exist yet, try again in 1 min')\n",
    "            time.sleep(60)\n",
    "\n",
    "print('Remapped file loaded: %s' % remap.filename)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get reciprocal space data from file\n",
    "h, k, l, vol = remap('h_axis, k_axis, l_axis, volume')\n",
    "# metadata\n",
    "title = scan.format('#{scan_number:.0f}: {(cmd|user_command|scan_command)}')\n",
    "hkl = scan.eval('array([h, k, l])')\n",
    "vol_hkl = np.array([h.mean(), k.mean(), l.mean()])\n",
    "pixel_size = remap('/entry0/instrument/pil3_100k/module/fast_pixel_direction')  # float, mm\n",
    "detector_distance = remap('/entry0/instrument/pil3_100k/transformations/origin_offset')  # float, mm\n",
    "# average angle subtended by each pixel\n",
    "solid_angle = pixel_size ** 2 / detector_distance ** 2  # sr\n",
    "vol = vol * solid_angle\n",
    "\n",
    "md(remap.format(\"\"\"\n",
    "## metadata\n",
    " - scan hkl: ({mean(diffractometer_sample_h):.3f}, {mean(diffractometer_sample_k):.3f}, {mean(diffractometer_sample_l):.3f})\n",
    " - volume hkl: ({mean(h_axis):.3f}, {mean(k_axis):.3f}, {mean(l_axis):.3f})\n",
    " - pixel_size: {s_fast_pixel_direction}\n",
    " - detector_distance: {s_origin_offset}\n",
    "## Reciprocal Space Volume\n",
    "- h_axis: {s_h_axis}\n",
    "- k_axis: {s_k_axis}\n",
    "- l_axis: {s_l_axis}\n",
    "- volume: {s_volume}\n",
    "\"\"\"))\n",
    "\n",
    "md(f'Each pixel is normalised by the solid angle: {solid_angle: .4g} sr\\n\\nThe max intensity is {vol.max():.4g} counts')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Volume Statistics"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Volume statistics\n",
    "nonzero_vol = vol[vol > 0]\n",
    "background = nonzero_vol.min() + 1\n",
    "signal = nonzero_vol.max() - background\n",
    "ii, ij, ik = fitting.max_index(vol)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot histogram\n",
    "cmap = plt.get_cmap()\n",
    "cut_ratios=(1e-3, 1e-2, 1e-1)  # lines at points relative to max intensity\n",
    "alphas = np.linspace(0.1, 1, len(cut_ratios))\n",
    "max_volume = vol.max()\n",
    "\n",
    "ax = plt.figure().add_subplot()\n",
    "n, bins, patches = ax.hist(np.log10(vol[vol > 0].flatten()), 100)\n",
    "mode_background = 10 ** bins[np.argmax(n)]\n",
    "\n",
    "for cut, alpha in zip(cut_ratios, alphas):\n",
    "    logval = np.log10(cut * max_volume)\n",
    "    ax.axvline(logval, marker='', c='k')\n",
    "    for patch in patches:\n",
    "        if patch.xy[0] >= logval:\n",
    "            patch.set_color(cmap(alpha))\n",
    "\n",
    "ax.axvline(np.log10(background), marker='', c='b')\n",
    "ax.axvline(np.log10(mode_background), marker='', c='r')\n",
    "\n",
    "ax.set_xlabel('Log$_{10}$ Voxel Intensity')\n",
    "ax.set_ylabel('N')\n",
    "ax.set_title(title)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "is_peak = (\n",
    "    vol[vol > mode_background].size / nonzero_vol.size > 0.05 and  # enough signal pixels to call a peak\n",
    "    signal > 3 * np.sqrt(background)\n",
    ")\n",
    "\n",
    "md(f\"\"\"\n",
    "- signal: {signal:.4g}\n",
    "- background: {background:.4g}\n",
    "- most common intensity == mode: {mode_background:.4g}\n",
    "- signal / sqrt(background): {signal / np.sqrt(background):.4g}\n",
    "- signal i,j,k = {int(ii), int(ij), int(ik)}\n",
    "- signal voxels = {nonzero_vol[nonzero_vol > mode_background].size} [{nonzero_vol[nonzero_vol > mode_background].size / nonzero_vol.size:.3%}]\n",
    "- is_peak: {is_peak}\n",
    "\"\"\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if is_peak:\n",
    "    L, K = np.meshgrid(l, k)\n",
    "    with np.errstate(divide='ignore'):\n",
    "        plt.pcolormesh(K, L, np.log10(vol[ii, :, :]))\n",
    "    plt.axvline(k[ij], c='k', ls=':', marker='')\n",
    "    plt.axhline(l[ik], c='k', ls=':', marker='')\n",
    "    plt.xlabel('k-axis (r.l.u.)')\n",
    "    plt.ylabel('l-axis (r.l.u.)')\n",
    "    plt.title(f'Max Intensity\\nh = {h[ii]:.3f}, k = {k[ij]:.3f}, l = {l[ik]:.3f}')\n",
    "    #plt.axis('image')\n",
    "    plt.colorbar(label='Log(Intensity)')\n",
    "else:\n",
    "    md('*No Peak found*')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a window around the peak\n",
    "if is_peak:\n",
    "    window_size = 10  # voxels\n",
    "    ws = (\n",
    "        slice(ii-window_size, ii+window_size),\n",
    "        slice(ij-window_size, ij+window_size),\n",
    "        slice(ik-window_size, ik+window_size),\n",
    "    )\n",
    "else:\n",
    "    ws = (slice(None), slice(None), slice(None))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot summed cuts\n",
    "plt.figure(figsize=(18, 8), dpi=60)\n",
    "plt.suptitle(title)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(h, vol[:, ws[1], ws[2]].sum(axis=1).sum(axis=1))\n",
    "plt.xlabel('h-axis (r.l.u.)')\n",
    "plt.ylabel('sum axes [1,2]')\n",
    "if is_peak:\n",
    "    plt.title(f'k = {k[ij]}, l = {l[ik]}')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(k, vol[ws[0], :, ws[2]].sum(axis=0).sum(axis=1))\n",
    "plt.xlabel('k-axis (r.l.u.)')\n",
    "plt.ylabel('sum axes [0,2]')\n",
    "if is_peak:\n",
    "    plt.title(f'h = {h[ii]}, l = {l[ik]}')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(l, vol[ws[0], ws[1], :].sum(axis=0).sum(axis=0))\n",
    "plt.xlabel('l-axis (r.l.u.)')\n",
    "plt.ylabel('sum axes [0,1]')\n",
    "if is_peak:\n",
    "    plt.title(f'h = {h[ii]}, k = {k[ij]}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot summed images\n",
    "plt.figure(figsize=(18, 8), dpi=60)\n",
    "title = scan.format('#{scan_number:.0f}: {(cmd|user_command|scan_command)}')\n",
    "plt.suptitle(title)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plt.subplot(131)\n",
    "K, H = np.meshgrid(k, h)\n",
    "plt.pcolormesh(H, K, vol[:, :, ws[2]].sum(axis=2), shading='gouraud')\n",
    "plt.xlabel('h-axis (r.l.u.)')\n",
    "plt.ylabel('k-axis (r.l.u.)')\n",
    "if is_peak:\n",
    "    plt.title(f'l = {l[ik]}')\n",
    "#plt.axis('image')\n",
    "#plt.colorbar()\n",
    "\n",
    "plt.subplot(132)\n",
    "L, H = np.meshgrid(l, h)\n",
    "plt.pcolormesh(H, L, vol[:, ws[1], :].sum(axis=1), shading='gouraud')\n",
    "plt.xlabel('h-axis (r.l.u.)')\n",
    "plt.ylabel('l-axis (r.l.u.)')\n",
    "if is_peak:\n",
    "    plt.title(f'k = {k[ij]}')\n",
    "#plt.axis('image')\n",
    "#plt.colorbar()\n",
    "\n",
    "plt.subplot(133)\n",
    "L, K = np.meshgrid(l, k)\n",
    "plt.pcolormesh(K, L, vol[ws[0], :, :].sum(axis=0), shading='gouraud')\n",
    "plt.xlabel('k-axis (r.l.u.)')\n",
    "plt.ylabel('l-axis (r.l.u.)')\n",
    "if is_peak:\n",
    "    plt.title(f'h = {h[ii]}')\n",
    "#plt.axis('image')\n",
    "plt.colorbar(label='Intensity (a.u.)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Peak Fitting"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if is_peak:\n",
    "    from mmg_toolbox.utils import fitting\n",
    "\n",
    "    # slices through the volume summed accross several pixels\n",
    "    h_slice = vol[:, ws[1], ws[2]].sum(axis=1).sum(axis=1) - mode_background\n",
    "    k_slice = vol[ws[0], :, ws[2]].sum(axis=0).sum(axis=1) - mode_background\n",
    "    l_slice = vol[ws[0], ws[1], :].sum(axis=0).sum(axis=0) - mode_background\n",
    "\n",
    "    # mask background\n",
    "    h_fit, h_slice_bk = h[h_slice > 0], h_slice[h_slice > 0]\n",
    "    k_fit, k_slice_bk = k[k_slice > 0], k_slice[k_slice > 0]\n",
    "    l_fit, l_slice_bk = l[l_slice > 0], l_slice[l_slice > 0]\n",
    "\n",
    "    options = dict(\n",
    "        npeaks = None,            # Number of peaks to fit (None==find peaks)\n",
    "        min_peak_power = None,    # signal/background > this to count as peak\n",
    "        peak_distance_idx = 10,   # peaks must be separated by this many points\n",
    "        model = 'pVoight',        # peak model, 'gaussian', 'lorentzian', 'voight', 'pvoight'\n",
    "        background = 'slope',     # 'slope', 'flat', 'exponential'\n",
    "        initial_parameters = None,# e.g. {'p1_center': 3.0}\n",
    "        fix_parameters = None,    # e.g. {'p1_center': 3.0}\n",
    "        method = 'leastsq',       # minimizer, 'leastsq', 'nelder', 'powell' etc\n",
    "        print_result = False,\n",
    "        plot_result = True\n",
    "    )\n",
    "\n",
    "    h_result = fitting.multipeakfit(h_fit, h_slice_bk, **options)\n",
    "    k_result = fitting.multipeakfit(k_fit, k_slice_bk, **options)\n",
    "    l_result = fitting.multipeakfit(l_fit, l_slice_bk, **options)\n",
    "\n",
    "    md('### h-axis')\n",
    "    print(h_result)\n",
    "    md('### k-axis')\n",
    "    print(k_result)\n",
    "    md('### l-axis')\n",
    "    print(l_result)\n",
    "else:\n",
    "    md('*No Peak Found*')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if is_peak:\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    ax1.plot(h, h_slice, 'bo-', label='Data')\n",
    "    ax1.plot(*h_result.fit_data(h), 'r-', label='Fit')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel('h (r.l.u.)')\n",
    "    ax1.set_ylabel('intensity (a.u.)')\n",
    "\n",
    "    ax2.plot(k, k_slice, 'bo-', label='Data')\n",
    "    ax2.plot(*k_result.fit_data(k), 'r-', label='Fit')\n",
    "    ax2.legend()\n",
    "    ax2.set_xlabel('k (r.l.u.)')\n",
    "    ax2.set_ylabel('intensity (a.u.)')\n",
    "\n",
    "    ax3.plot(l, l_slice, 'bo-', label='Data')\n",
    "    ax3.plot(*l_result.fit_data(l), 'r-', label='Fit')\n",
    "    ax3.legend()\n",
    "    ax3.set_xlabel('l (r.l.u.)')\n",
    "    ax3.set_ylabel('intensity (a.u.)')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if is_peak:\n",
    "    table = \"|  | Amplitude | Centre (r.l.u.) | FWHM (r.l.u.) | Background |\\n\"\n",
    "    table += \"| --- | --- | --- | --- | --- |\\n\"\n",
    "    table += f\"| h | {h_result.get_string('amplitude')} | {h_result.get_string('center')} | {h_result.get_string('fwhm')} | {h_result.get_string('background')} |\\n\"\n",
    "    table += f\"| k | {k_result.get_string('amplitude')} | {k_result.get_string('center')} | {k_result.get_string('fwhm')} | {k_result.get_string('background')} |\\n\"\n",
    "    table += f\"| l | {l_result.get_string('amplitude')} | {l_result.get_string('center')} | {l_result.get_string('fwhm')} | {l_result.get_string('background')} |\\n\"\n",
    "\n",
    "    md(table)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to cartesian coordinates (Q)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fail if hkl values are not consistent\n",
    "assert np.linalg.norm(vol_hkl - hkl) < 0.5, f\"Measured hkl={hkl} is different from remapped hkl={vol_hkl}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from mmg_toolbox.diffraction.lattice import bmatrix, cal2theta\n",
    "\n",
    "# Convert to Q\n",
    "a, b, c, alpha, beta, gamma = scan('unit_cell')\n",
    "energy = scan('incident_energy')\n",
    "\n",
    "# Build reciprocal lattice in orthogonal basis\n",
    "astar, bstar, cstar = bmatrix(a, b, c, alpha, beta, gamma)\n",
    "kk, hh, ll = np.meshgrid(k, h, l)\n",
    "q = astar * hh.reshape(-1, 1) + bstar * kk.reshape(-1, 1) + cstar * ll.reshape(-1, 1)\n",
    "qx = q[:, 0].reshape(hh.shape)\n",
    "qy = q[:, 1].reshape(hh.shape)\n",
    "qz = q[:, 2].reshape(hh.shape)\n",
    "# magnitude of wavevector-transfer Q=kf-ki\n",
    "qmag = np.sqrt(qx **2 + qy ** 2 + qz **2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot summed images\n",
    "plt.figure(figsize=(18, 8), dpi=60)\n",
    "plt.suptitle(title)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.pcolormesh(qx.mean(axis=2), qy.mean(axis=2), vol[:, :, ws[2]].sum(axis=2), shading='gouraud')\n",
    "plt.xlabel('Qx [A$^{-1}$]')\n",
    "plt.ylabel('Qy [A$^{-1}$]')\n",
    "plt.axis('image')\n",
    "#plt.colorbar()\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.pcolormesh(qx.mean(axis=1), qz.mean(axis=1), vol[:, ws[1], :].sum(axis=1), shading='gouraud')\n",
    "plt.xlabel('Qx [A$^{-1}$]')\n",
    "plt.ylabel('Qz [A$^{-1}$]')\n",
    "plt.axis('image')\n",
    "#plt.colorbar()\n",
    "\n",
    "plt.subplot(133)\n",
    "L, K = np.meshgrid(l, k)\n",
    "plt.pcolormesh(qy.mean(axis=0), qz.mean(axis=0), vol[ws[0], :, :].sum(axis=0), shading='gouraud')\n",
    "plt.xlabel('Qy [A$^{-1}$]')\n",
    "plt.ylabel('Qz [A$^{-1}$]')\n",
    "plt.axis('image')\n",
    "plt.colorbar()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### |Q| and Two-Theta plots"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "qmag2 = qmag.reshape(-1)\n",
    "qvol = vol.reshape(-1)\n",
    "qdiff = max(np.diff(qmag2))\n",
    "bin_cen = np.arange(qmag2.min(), qmag2.max(), qdiff)\n",
    "bin_edge = bin_cen + 0.005\n",
    "bin_pos = np.digitize(qmag2, bin_edge) -1\n",
    "bin_sum = np.array([np.mean(qvol[ii]) if any(ii := bin_pos==n) else 0 for n in range(len(bin_cen))])\n",
    "tth = cal2theta(bin_cen, energy)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fitting\n",
    "if is_peak:\n",
    "    window = slice(10, -10) # remove edges after removing zeros\n",
    "    q_result = fitting.multipeakfit(bin_cen[bin_sum > 0][window], bin_sum[bin_sum > 0][window], **options)\n",
    "    tth_result = fitting.multipeakfit(tth[bin_sum > 0][window], bin_sum[bin_sum > 0][window], **options)\n",
    "\n",
    "    md('### Q')\n",
    "    print(q_result)\n",
    "    md('### Two-Theta')\n",
    "    print(tth_result)\n",
    "else:\n",
    "    md('*No Peak Found*')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "title2 = scan.format('#{scan_number:.0f}\\n{(cmd|user_command|scan_command)}')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bin_cen, bin_sum, label='data')\n",
    "if is_peak:\n",
    "    plt.plot(*q_result.fit_data(bin_cen), 'r-', label='fit')\n",
    "    plt.legend()\n",
    "\n",
    "plt.title(title2)\n",
    "plt.xlabel('|Q| A$^{-1}$')\n",
    "plt.ylabel('Intensity')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tth, bin_sum, label='data')\n",
    "if is_peak:\n",
    "    plt.plot(*tth_result.fit_data(tth), 'r-', label='fit')\n",
    "    plt.legend()\n",
    "plt.title(title2)\n",
    "plt.xlabel('Two-Theta [Deg]')\n",
    "plt.ylabel('Intensity')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plot Geometry"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "instrument = scan.instrument_model()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "instrument.plot_wavevectors(ax)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Update Processed NeXus file"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from mmg_toolbox.diffraction.msmapper import update_msmapper_nexus\n",
    "\n",
    "update_msmapper_nexus(\n",
    "    filename=remap.filename,\n",
    "    hkl_slice=(h_slice, k_slice, l_slice),\n",
    "    orthogonal_axes=(qx, qy, qz),\n",
    "    average_axes=(bin_cen, tth, bin_sum),\n",
    "    fit_options=options if is_peak else None,\n",
    "    h_result=h_result if is_peak else None,\n",
    "    k_result=k_result if is_peak else None,\n",
    "    l_result=l_result if is_peak else None,\n",
    "    q_result=q_result if is_peak else None,\n",
    "    tth_result=tth_result if is_peak else None,\n",
    ")\n",
    "\n",
    "print(f\"Updated {remap.filename}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check updated file\n",
    "new = data_file_reader(remap.filename)\n",
    "print(new)\n",
    "new.plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# notify GDA-Datavis that the file exists\n",
    "# (this just sends a message, the GDA-DataVis perspective must be open for this to appear)\n",
    "try:\n",
    "    from mmg_toolbox.utils.gda_functions import gda_datavis_file_message\n",
    "    gda_datavis_file_message(remap.filename)\n",
    "except ImportError:\n",
    "    print('Not running on beamline!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
